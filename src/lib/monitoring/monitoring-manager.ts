// ç”Ÿäº§çº§ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ
import { PrismaClient } from '@prisma/client'
import { RedisCacheManager } from '../cache/redis-manager'
import { performance } from 'perf_hooks'

// æ—¥å¿—çº§åˆ«
enum LogLevel {
  ERROR = 0,
  WARN = 1,
  INFO = 2,
  DEBUG = 3,
  TRACE = 4
}

// æŒ‡æ ‡ç±»å‹
enum MetricType {
  COUNTER = 'counter',
  GAUGE = 'gauge',
  HISTOGRAM = 'histogram',
  TIMER = 'timer'
}

// æ—¥å¿—æ¡ç›®
interface LogEntry {
  timestamp: Date
  level: LogLevel
  message: string
  context?: Record<string, any>
  error?: Error
  trace?: string
  userId?: string
  sessionId?: string
  requestId?: string
  component: string
}

// æŒ‡æ ‡æ•°æ®
interface MetricData {
  name: string
  type: MetricType
  value: number
  labels?: Record<string, string>
  timestamp: Date
}

// æ€§èƒ½æŒ‡æ ‡
interface PerformanceMetric {
  name: string
  duration: number
  startTime: number
  endTime: number
  labels?: Record<string, string>
}

// è­¦æŠ¥è§„åˆ™
interface AlertRule {
  id: string
  name: string
  condition: string
  threshold: number
  duration: number // æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
  enabled: boolean
  severity: 'low' | 'medium' | 'high' | 'critical'
  actions: AlertAction[]
}

interface AlertAction {
  type: 'email' | 'webhook' | 'slack'
  config: Record<string, any>
}

// ç›‘æ§ç®¡ç†å™¨
export class MonitoringManager {
  private prisma: PrismaClient
  private cache: RedisCacheManager
  private logLevel: LogLevel
  private metricsBuffer: MetricData[] = []
  private logsBuffer: LogEntry[] = []
  private performanceTrackers = new Map<string, number>()
  private alertRules: AlertRule[] = []
  private alertStates = new Map<string, { triggered: boolean; since: Date }>()

  // é…ç½®
  private readonly config = {
    bufferSize: 1000,
    flushInterval: 10000, // 10ç§’
    metricsRetention: 7 * 24 * 3600, // 7å¤©
    logsRetention: 30 * 24 * 3600, // 30å¤©
    enableConsoleOutput: process.env.NODE_ENV === 'development'
  }

  constructor(
    prisma: PrismaClient,
    cache: RedisCacheManager,
    logLevel: LogLevel = LogLevel.INFO
  ) {
    this.prisma = prisma
    this.cache = cache
    this.logLevel = logLevel

    this.initializeAlertRules()
    this.startPeriodicFlush()
    this.startMetricsCollection()
  }

  // ==================== æ—¥å¿—ç³»ç»Ÿ ====================

  error(message: string, context?: Record<string, any>, error?: Error): void {
    this.log(LogLevel.ERROR, message, context, error)
  }

  warn(message: string, context?: Record<string, any>): void {
    this.log(LogLevel.WARN, message, context)
  }

  info(message: string, context?: Record<string, any>): void {
    this.log(LogLevel.INFO, message, context)
  }

  debug(message: string, context?: Record<string, any>): void {
    this.log(LogLevel.DEBUG, message, context)
  }

  trace(message: string, context?: Record<string, any>): void {
    this.log(LogLevel.TRACE, message, context)
  }

  private log(
    level: LogLevel,
    message: string,
    context?: Record<string, any>,
    error?: Error,
    component: string = 'system'
  ): void {
    if (level > this.logLevel) return

    const logEntry: LogEntry = {
      timestamp: new Date(),
      level,
      message,
      context,
      error,
      trace: error?.stack,
      userId: context?.userId,
      sessionId: context?.sessionId,
      requestId: context?.requestId,
      component
    }

    // æ§åˆ¶å°è¾“å‡º
    if (this.config.enableConsoleOutput) {
      this.outputToConsole(logEntry)
    }

    // æ·»åŠ åˆ°ç¼“å†²åŒº
    this.logsBuffer.push(logEntry)

    // å¦‚æœæ˜¯é”™è¯¯çº§åˆ«ï¼Œç«‹å³è§¦å‘å‘Šè­¦æ£€æŸ¥
    if (level === LogLevel.ERROR) {
      this.checkErrorAlerts(logEntry)
    }

    // ç¼“å†²åŒºæ»¡æ—¶å¼ºåˆ¶åˆ·æ–°
    if (this.logsBuffer.length >= this.config.bufferSize) {
      this.flushLogs()
    }
  }

  private outputToConsole(entry: LogEntry): void {
    const levelNames = ['ERROR', 'WARN', 'INFO', 'DEBUG', 'TRACE']
    const colors = ['\x1b[31m', '\x1b[33m', '\x1b[32m', '\x1b[36m', '\x1b[90m']
    const reset = '\x1b[0m'

    const timestamp = entry.timestamp.toISOString()
    const level = levelNames[entry.level]
    const color = colors[entry.level]

    let output = `${color}[${timestamp}] ${level}: ${entry.message}${reset}`

    if (entry.context) {
      output += `\n  Context: ${JSON.stringify(entry.context, null, 2)}`
    }

    if (entry.error) {
      output += `\n  Error: ${entry.error.message}`
      if (entry.trace) {
        output += `\n  Stack: ${entry.trace}`
      }
    }

    console.log(output)
  }

  // ==================== æŒ‡æ ‡ç³»ç»Ÿ ====================

  counter(name: string, value: number = 1, labels?: Record<string, string>): void {
    this.recordMetric({
      name,
      type: MetricType.COUNTER,
      value,
      labels,
      timestamp: new Date()
    })
  }

  gauge(name: string, value: number, labels?: Record<string, string>): void {
    this.recordMetric({
      name,
      type: MetricType.GAUGE,
      value,
      labels,
      timestamp: new Date()
    })
  }

  histogram(name: string, value: number, labels?: Record<string, string>): void {
    this.recordMetric({
      name,
      type: MetricType.HISTOGRAM,
      value,
      labels,
      timestamp: new Date()
    })
  }

  private recordMetric(metric: MetricData): void {
    this.metricsBuffer.push(metric)

    // åŒæ—¶æ›´æ–°Redisä¸­çš„å®æ—¶æŒ‡æ ‡
    this.updateRealtimeMetric(metric)

    // æ£€æŸ¥æŒ‡æ ‡è­¦æŠ¥
    this.checkMetricAlerts(metric)

    // ç¼“å†²åŒºæ»¡æ—¶å¼ºåˆ¶åˆ·æ–°
    if (this.metricsBuffer.length >= this.config.bufferSize) {
      this.flushMetrics()
    }
  }

  private async updateRealtimeMetric(metric: MetricData): Promise<void> {
    const key = `metrics:${metric.name}:${JSON.stringify(metric.labels || {})}`

    try {
      if (metric.type === MetricType.COUNTER) {
        await this.cache['redis'].incrbyfloat(key, metric.value)
      } else {
        await this.cache['redis'].set(key, metric.value)
      }

      await this.cache['redis'].expire(key, 3600) // 1å°æ—¶è¿‡æœŸ
    } catch (error) {
      console.error('Failed to update realtime metric:', error)
    }
  }

  // ==================== æ€§èƒ½ç›‘æ§ ====================

  startTimer(name: string, labels?: Record<string, string>): string {
    const trackerId = `${name}_${Date.now()}_${Math.random()}`
    this.performanceTrackers.set(trackerId, performance.now())

    return trackerId
  }

  endTimer(trackerId: string, labels?: Record<string, string>): number {
    const startTime = this.performanceTrackers.get(trackerId)
    if (!startTime) return 0

    const duration = performance.now() - startTime
    this.performanceTrackers.delete(trackerId)

    // è®°å½•ä¸ºç›´æ–¹å›¾æŒ‡æ ‡
    const name = trackerId.split('_')[0] + '_duration_ms'
    this.histogram(name, duration, labels)

    return duration
  }

  // æ€§èƒ½è£…é¥°å™¨
  measurePerformance<T extends (...args: any[]) => Promise<any>>(
    fn: T,
    metricName: string,
    getLabels?: (...args: any[]) => Record<string, string>
  ): T {
    return (async (...args: any[]) => {
      const labels = getLabels?.(...args) || {}
      const trackerId = this.startTimer(metricName, labels)

      try {
        const result = await fn(...args)
        this.endTimer(trackerId, labels)
        this.counter(`${metricName}_success_total`, 1, labels)
        return result
      } catch (error) {
        this.endTimer(trackerId, labels)
        this.counter(`${metricName}_error_total`, 1, labels)
        throw error
      }
    }) as T
  }

  // ==================== å¥åº·æ£€æŸ¥ ====================

  async getSystemHealth(): Promise<{
    status: 'healthy' | 'degraded' | 'unhealthy'
    checks: Record<string, {
      status: 'pass' | 'fail'
      message?: string
      responseTime?: number
    }>
    uptime: number
    version: string
  }> {
    const startTime = Date.now()
    const checks: Record<string, any> = {}

    // æ•°æ®åº“æ£€æŸ¥
    try {
      await this.prisma.$queryRaw`SELECT 1`
      checks.database = {
        status: 'pass',
        responseTime: Date.now() - startTime
      }
    } catch (error) {
      checks.database = {
        status: 'fail',
        message: (error as Error).message
      }
    }

    // Redisæ£€æŸ¥
    const redisHealth = await this.cache.healthCheck()
    checks.redis = {
      status: redisHealth.healthy ? 'pass' : 'fail',
      message: redisHealth.error,
      responseTime: redisHealth.latency
    }

    // å†…å­˜æ£€æŸ¥
    const memUsage = process.memoryUsage()
    const memUsageMB = Math.round(memUsage.rss / 1024 / 1024)
    checks.memory = {
      status: memUsageMB < 1024 ? 'pass' : 'fail', // 1GBé™åˆ¶
      message: `${memUsageMB}MB used`
    }

    // CPUæ£€æŸ¥
    const cpuUsage = process.cpuUsage()
    checks.cpu = {
      status: 'pass',
      message: `User: ${cpuUsage.user}Âµs, System: ${cpuUsage.system}Âµs`
    }

    // ç¡®å®šæ•´ä½“çŠ¶æ€
    const failedChecks = Object.values(checks).filter(check => check.status === 'fail').length
    let status: 'healthy' | 'degraded' | 'unhealthy'

    if (failedChecks === 0) {
      status = 'healthy'
    } else if (failedChecks === 1) {
      status = 'degraded'
    } else {
      status = 'unhealthy'
    }

    return {
      status,
      checks,
      uptime: process.uptime(),
      version: process.env.npm_package_version || '1.0.0'
    }
  }

  // ==================== è­¦æŠ¥ç³»ç»Ÿ ====================

  private initializeAlertRules(): void {
    this.alertRules = [
      {
        id: 'high_error_rate',
        name: 'é”™è¯¯ç‡è¿‡é«˜',
        condition: 'error_total > 10',
        threshold: 10,
        duration: 300, // 5åˆ†é’Ÿ
        enabled: true,
        severity: 'high',
        actions: [
          {
            type: 'email',
            config: { recipients: ['admin@example.com'] }
          }
        ]
      },
      {
        id: 'slow_response_time',
        name: 'å“åº”æ—¶é—´è¿‡æ…¢',
        condition: 'avg(request_duration_ms) > 2000',
        threshold: 2000,
        duration: 600, // 10åˆ†é’Ÿ
        enabled: true,
        severity: 'medium',
        actions: [
          {
            type: 'webhook',
            config: { url: 'https://hooks.slack.com/...' }
          }
        ]
      },
      {
        id: 'memory_usage_high',
        name: 'å†…å­˜ä½¿ç”¨è¿‡é«˜',
        condition: 'memory_usage_mb > 800',
        threshold: 800,
        duration: 180, // 3åˆ†é’Ÿ
        enabled: true,
        severity: 'critical',
        actions: [
          {
            type: 'email',
            config: { recipients: ['ops@example.com'] }
          }
        ]
      }
    ]
  }

  private checkMetricAlerts(metric: MetricData): void {
    this.alertRules.forEach(rule => {
      if (!rule.enabled) return

      // ç®€åŒ–çš„è§„åˆ™åŒ¹é…ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å¤æ‚çš„è§„åˆ™å¼•æ“ï¼‰
      const shouldTrigger = this.evaluateAlertRule(rule, metric)

      if (shouldTrigger) {
        this.triggerAlert(rule, metric)
      }
    })
  }

  private checkErrorAlerts(logEntry: LogEntry): void {
    const errorRule = this.alertRules.find(rule => rule.id === 'high_error_rate')
    if (errorRule && errorRule.enabled) {
      this.counter('error_total', 1)
    }
  }

  private evaluateAlertRule(rule: AlertRule, metric: MetricData): boolean {
    // è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„è§„åˆ™å¼•æ“
    if (rule.condition.includes(metric.name)) {
      return metric.value > rule.threshold
    }
    return false
  }

  private triggerAlert(rule: AlertRule, metric: MetricData): void {
    const alertKey = `alert:${rule.id}`
    const state = this.alertStates.get(alertKey)

    if (!state || !state.triggered) {
      // æ–°è­¦æŠ¥æˆ–ä¹‹å‰å·²æ¢å¤çš„è­¦æŠ¥
      this.alertStates.set(alertKey, { triggered: true, since: new Date() })

      this.error('Alert triggered', {
        ruleId: rule.id,
        ruleName: rule.name,
        severity: rule.severity,
        metric: metric.name,
        value: metric.value,
        threshold: rule.threshold
      })

      // æ‰§è¡Œè­¦æŠ¥åŠ¨ä½œ
      rule.actions.forEach(action => {
        this.executeAlertAction(action, rule, metric)
      })
    }
  }

  private executeAlertAction(action: AlertAction, rule: AlertRule, metric: MetricData): void {
    switch (action.type) {
      case 'email':
        this.sendEmailAlert(action.config, rule, metric)
        break
      case 'webhook':
        this.sendWebhookAlert(action.config, rule, metric)
        break
      case 'slack':
        this.sendSlackAlert(action.config, rule, metric)
        break
    }
  }

  private sendEmailAlert(config: any, rule: AlertRule, metric: MetricData): void {
    // å®é™…å®ç°ä¸­åº”é›†æˆé‚®ä»¶æœåŠ¡
    this.info('Email alert sent', {
      recipients: config.recipients,
      subject: `[${rule.severity.toUpperCase()}] ${rule.name}`,
      content: `Metric ${metric.name} value ${metric.value} exceeded threshold ${rule.threshold}`
    })
  }

  private sendWebhookAlert(config: any, rule: AlertRule, metric: MetricData): void {
    // å®é™…å®ç°ä¸­åº”å‘é€HTTPè¯·æ±‚
    this.info('Webhook alert sent', {
      url: config.url,
      payload: {
        rule: rule.name,
        severity: rule.severity,
        metric: metric.name,
        value: metric.value,
        threshold: rule.threshold
      }
    })
  }

  private sendSlackAlert(config: any, rule: AlertRule, metric: MetricData): void {
    // å®é™…å®ç°ä¸­åº”è°ƒç”¨Slack API
    this.info('Slack alert sent', {
      channel: config.channel,
      message: `ğŸš¨ ${rule.name}: ${metric.name} = ${metric.value} (threshold: ${rule.threshold})`
    })
  }

  // ==================== æ•°æ®æŒä¹…åŒ– ====================

  private async flushLogs(): Promise<void> {
    if (this.logsBuffer.length === 0) return

    const logsToFlush = [...this.logsBuffer]
    this.logsBuffer = []

    try {
      // æ‰¹é‡ä¿å­˜åˆ°Redisï¼ˆç”¨äºå®æ—¶æŸ¥è¯¢ï¼‰
      const pipeline = this.cache['redis'].pipeline()

      logsToFlush.forEach(log => {
        const key = `logs:${log.timestamp.getTime()}`
        pipeline.set(key, JSON.stringify(log), 'EX', this.config.logsRetention)
      })

      await pipeline.exec()

      // é”™è¯¯æ—¥å¿—é¢å¤–ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆæŒä¹…åŒ–ï¼‰
      const errorLogs = logsToFlush.filter(log => log.level === LogLevel.ERROR)
      if (errorLogs.length > 0) {
        // è¿™é‡Œå¯ä»¥ä¿å­˜åˆ°ä¸“é—¨çš„é”™è¯¯æ—¥å¿—è¡¨
        this.info(`Saved ${errorLogs.length} error logs to database`)
      }

    } catch (error) {
      console.error('Failed to flush logs:', error)
      // å¤±è´¥çš„æ—¥å¿—é‡æ–°åŠ å›ç¼“å†²åŒº
      this.logsBuffer.unshift(...logsToFlush)
    }
  }

  private async flushMetrics(): Promise<void> {
    if (this.metricsBuffer.length === 0) return

    const metricsToFlush = [...this.metricsBuffer]
    this.metricsBuffer = []

    try {
      // æ‰¹é‡ä¿å­˜æŒ‡æ ‡åˆ°æ—¶é—´åºåˆ—å­˜å‚¨ï¼ˆè¿™é‡Œä½¿ç”¨Redisç¤ºä¾‹ï¼‰
      const pipeline = this.cache['redis'].pipeline()

      metricsToFlush.forEach(metric => {
        const key = `metrics:timeseries:${metric.name}`
        const timestamp = metric.timestamp.getTime()

        // ä½¿ç”¨Redisçš„Sorted Setå­˜å‚¨æ—¶é—´åºåˆ—æ•°æ®
        pipeline.zadd(key, timestamp, `${timestamp}:${metric.value}:${JSON.stringify(metric.labels || {})}`)
        pipeline.expire(key, this.config.metricsRetention)
      })

      await pipeline.exec()

    } catch (error) {
      console.error('Failed to flush metrics:', error)
      this.metricsBuffer.unshift(...metricsToFlush)
    }
  }

  // ==================== å®šæœŸä»»åŠ¡ ====================

  private startPeriodicFlush(): void {
    setInterval(() => {
      this.flushLogs()
      this.flushMetrics()
    }, this.config.flushInterval)
  }

  private startMetricsCollection(): void {
    setInterval(() => {
      this.collectSystemMetrics()
    }, 30000) // æ¯30ç§’æ”¶é›†ä¸€æ¬¡ç³»ç»ŸæŒ‡æ ‡
  }

  private collectSystemMetrics(): void {
    // å†…å­˜ä½¿ç”¨
    const memUsage = process.memoryUsage()
    this.gauge('memory_usage_mb', Math.round(memUsage.rss / 1024 / 1024))
    this.gauge('memory_heap_used_mb', Math.round(memUsage.heapUsed / 1024 / 1024))
    this.gauge('memory_heap_total_mb', Math.round(memUsage.heapTotal / 1024 / 1024))

    // CPUä½¿ç”¨
    const cpuUsage = process.cpuUsage()
    this.gauge('cpu_user_microseconds', cpuUsage.user)
    this.gauge('cpu_system_microseconds', cpuUsage.system)

    // è¿è¡Œæ—¶é—´
    this.gauge('uptime_seconds', process.uptime())

    // æ´»è·ƒå¥æŸ„æ•°
    this.gauge('active_handles', (process as any)._getActiveHandles()?.length || 0)
    this.gauge('active_requests', (process as any)._getActiveRequests()?.length || 0)
  }

  // ==================== æŸ¥è¯¢æ¥å£ ====================

  async getMetrics(
    metricName: string,
    startTime: Date,
    endTime: Date,
    labels?: Record<string, string>
  ): Promise<Array<{ timestamp: number; value: number }>> {
    try {
      const key = `metrics:timeseries:${metricName}`
      const start = startTime.getTime()
      const end = endTime.getTime()

      const results = await this.cache['redis'].zrangebyscore(key, start, end)

      return results.map(result => {
        const [timestamp, value] = result.split(':')
        return {
          timestamp: parseInt(timestamp),
          value: parseFloat(value)
        }
      }).filter(item => !isNaN(item.value))

    } catch (error) {
      console.error('Failed to get metrics:', error)
      return []
    }
  }

  async getLogs(
    startTime: Date,
    endTime: Date,
    level?: LogLevel,
    component?: string
  ): Promise<LogEntry[]> {
    try {
      const pattern = 'logs:*'
      const keys = await this.cache['redis'].keys(pattern)

      if (keys.length === 0) return []

      const pipeline = this.cache['redis'].pipeline()
      keys.forEach(key => pipeline.get(key))

      const results = await pipeline.exec()
      const logs: LogEntry[] = []

      results?.forEach(result => {
        if (result[1]) {
          try {
            const log = JSON.parse(result[1] as string) as LogEntry
            const logTime = new Date(log.timestamp)

            if (logTime >= startTime && logTime <= endTime) {
              if (!level || log.level === level) {
                if (!component || log.component === component) {
                  logs.push(log)
                }
              }
            }
          } catch (error) {
            console.error('Failed to parse log entry:', error)
          }
        }
      })

      return logs.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime())

    } catch (error) {
      console.error('Failed to get logs:', error)
      return []
    }
  }

  // ==================== ä¼˜é›…å…³é—­ ====================

  async shutdown(): Promise<void> {
    this.info('MonitoringManager shutting down...')

    // åˆ·æ–°å‰©ä½™çš„ç¼“å†²åŒºæ•°æ®
    await this.flushLogs()
    await this.flushMetrics()

    this.info('MonitoringManager shutdown completed')
  }
}

// åˆ›å»ºå…¨å±€ç›‘æ§å®ä¾‹
let monitoringInstance: MonitoringManager | null = null

export function getMonitoringManager(
  prisma: PrismaClient,
  cache: RedisCacheManager,
  logLevel?: LogLevel
): MonitoringManager {
  if (!monitoringInstance) {
    monitoringInstance = new MonitoringManager(prisma, cache, logLevel)
  }
  return monitoringInstance
}

// å¯¼å‡ºç±»å‹å’Œæšä¸¾
export { LogLevel, MetricType }
export type { LogEntry, MetricData, PerformanceMetric, AlertRule }