/**
 * éŸ³æ•ˆç”Ÿæˆå™¨å·¥å…·
 *
 * ä½¿ç”¨Web Audio APIç”Ÿæˆç®€å•çš„éŸ³æ•ˆ
 * ç”¨ä½œå¼€å‘é˜¶æ®µçš„éŸ³æ•ˆå ä½ç¬¦
 */

export type SoundType =
  // ç°æœ‰éŸ³æ•ˆ
  | 'assessment-complete'
  | 'workshop-unlock'
  | 'button-click'
  | 'score-tick'
  | 'transition-whoosh'
  // æ–°å¢å·¥ä½œåŠéŸ³æ•ˆ
  | 'step-complete'
  | 'form-save'
  | 'agent-message'
  | 'pdf-download'
  | 'workshop-start'

// éŸ³æ•ˆå‚æ•°é…ç½®
interface SoundConfig {
  type: 'beep' | 'chord' | 'sweep' | 'tick' | 'whoosh' | 'ding'
  frequency: number
  duration: number
  volume: number
  fadeOut?: boolean
}

// éŸ³æ•ˆé…ç½®æ˜ å°„
const SOUND_CONFIGS: Record<SoundType, SoundConfig> = {
  // è¯„ä¼°ç³»ç»ŸéŸ³æ•ˆ
  'assessment-complete': {
    type: 'ding',
    frequency: 800,
    duration: 1.2,
    volume: 0.5,
    fadeOut: true
  },
  'workshop-unlock': {
    type: 'chord',
    frequency: 523, // C5
    duration: 2.0,
    volume: 0.6,
    fadeOut: true
  },
  'button-click': {
    type: 'tick',
    frequency: 1000,
    duration: 0.1,
    volume: 0.3
  },
  'score-tick': {
    type: 'beep',
    frequency: 880,
    duration: 0.05,
    volume: 0.2
  },
  'transition-whoosh': {
    type: 'whoosh',
    frequency: 300,
    duration: 0.8,
    volume: 0.4,
    fadeOut: true
  },

  // å·¥ä½œåŠæ–°éŸ³æ•ˆ
  'step-complete': {
    type: 'ding',
    frequency: 659, // E5
    duration: 0.8,
    volume: 0.5,
    fadeOut: true
  },
  'form-save': {
    type: 'beep',
    frequency: 440, // A4
    duration: 0.3,
    volume: 0.3
  },
  'agent-message': {
    type: 'sweep',
    frequency: 600,
    duration: 0.5,
    volume: 0.3,
    fadeOut: true
  },
  'pdf-download': {
    type: 'chord',
    frequency: 698, // F5
    duration: 1.5,
    volume: 0.5,
    fadeOut: true
  },
  'workshop-start': {
    type: 'chord',
    frequency: 587, // D5
    duration: 1.8,
    volume: 0.6,
    fadeOut: true
  }
}

/**
 * ç”ŸæˆéŸ³æ•ˆçš„æ ¸å¿ƒå‡½æ•°
 */
export function generateSound(soundType: SoundType): Promise<AudioBuffer> {
  return new Promise((resolve, reject) => {
    try {
      const config = SOUND_CONFIGS[soundType]
      const audioContext = new AudioContext()
      const sampleRate = audioContext.sampleRate
      const length = sampleRate * config.duration
      const buffer = audioContext.createBuffer(1, length, sampleRate)
      const data = buffer.getChannelData(0)

      // æ ¹æ®éŸ³æ•ˆç±»å‹ç”Ÿæˆæ³¢å½¢
      for (let i = 0; i < length; i++) {
        const time = i / sampleRate
        const amplitude = config.volume

        let sample = 0

        switch (config.type) {
          case 'beep':
            sample = Math.sin(2 * Math.PI * config.frequency * time) * amplitude
            break

          case 'ding':
            // å¸¦è¡°å‡çš„æ­£å¼¦æ³¢
            const decay = Math.exp(-time * 3)
            sample = Math.sin(2 * Math.PI * config.frequency * time) * amplitude * decay
            break

          case 'chord':
            // ä¸‰å’Œå¼¦ï¼ˆæ ¹éŸ³ã€ä¸‰åº¦ã€äº”åº¦ï¼‰
            const root = Math.sin(2 * Math.PI * config.frequency * time)
            const third = Math.sin(2 * Math.PI * config.frequency * 1.25 * time)
            const fifth = Math.sin(2 * Math.PI * config.frequency * 1.5 * time)
            const chordDecay = Math.exp(-time * 1.5)
            sample = (root + third * 0.7 + fifth * 0.5) * amplitude * 0.4 * chordDecay
            break

          case 'sweep':
            // é¢‘ç‡æ‰«æ
            const sweepFreq = config.frequency + (config.frequency * 0.5 * time / config.duration)
            const sweepDecay = Math.exp(-time * 2)
            sample = Math.sin(2 * Math.PI * sweepFreq * time) * amplitude * sweepDecay
            break

          case 'tick':
            // çŸ­ä¿ƒçš„è„‰å†²
            if (time < 0.02) {
              sample = Math.sin(2 * Math.PI * config.frequency * time) * amplitude
            } else {
              sample = 0
            }
            break

          case 'whoosh':
            // å™ªå£°æ‰«é¢‘
            const noise = (Math.random() - 0.5) * 2
            const whooshFreq = config.frequency * (1 + time / config.duration)
            const whooshFilter = Math.sin(2 * Math.PI * whooshFreq * time)
            const whooshEnv = Math.exp(-time * 2) * (1 - time / config.duration)
            sample = noise * whooshFilter * amplitude * whooshEnv * 0.3
            break
        }

        // åº”ç”¨æ·¡å‡ºæ•ˆæœ
        if (config.fadeOut && time > config.duration * 0.7) {
          const fadeProgress = (time - config.duration * 0.7) / (config.duration * 0.3)
          sample *= (1 - fadeProgress)
        }

        data[i] = sample
      }

      resolve(buffer)
      audioContext.close()
    } catch (error) {
      reject(error)
    }
  })
}

/**
 * åˆ›å»ºéŸ³æ•ˆæ’­æ”¾å™¨
 */
export class SoundPlayer {
  private audioContext: AudioContext | null = null
  private soundCache: Map<SoundType, AudioBuffer> = new Map()
  private masterVolume = 0.5
  private enabled = false

  constructor(enabled = false, volume = 0.5) {
    this.enabled = enabled
    this.masterVolume = Math.max(0, Math.min(1, volume))

    if (typeof window !== 'undefined' && this.enabled) {
      this.initAudioContext()
    }
  }

  private initAudioContext() {
    try {
      this.audioContext = new AudioContext()
    } catch (error) {
      console.warn('ğŸ”‡ æ— æ³•åˆ›å»ºAudioContext:', error)
      this.enabled = false
    }
  }

  /**
   * é¢„åŠ è½½éŸ³æ•ˆ
   */
  async preloadSound(soundType: SoundType): Promise<void> {
    if (!this.enabled || !this.audioContext) return

    if (this.soundCache.has(soundType)) return

    try {
      const buffer = await generateSound(soundType)
      this.soundCache.set(soundType, buffer)
      console.log(`ğŸ”Š éŸ³æ•ˆé¢„åŠ è½½å®Œæˆ: ${soundType}`)
    } catch (error) {
      console.warn(`ğŸ”‡ éŸ³æ•ˆé¢„åŠ è½½å¤±è´¥: ${soundType}`, error)
    }
  }

  /**
   * æ’­æ”¾éŸ³æ•ˆ
   */
  async playSound(soundType: SoundType): Promise<void> {
    if (!this.enabled || !this.audioContext) {
      console.log(`ğŸ”‡ éŸ³æ•ˆå·²ç¦ç”¨: ${soundType}`)
      return
    }

    try {
      // å¦‚æœéŸ³æ•ˆæœªç¼“å­˜ï¼Œå…ˆç”Ÿæˆ
      if (!this.soundCache.has(soundType)) {
        await this.preloadSound(soundType)
      }

      const buffer = this.soundCache.get(soundType)
      if (!buffer) return

      // åˆ›å»ºéŸ³é¢‘èŠ‚ç‚¹
      const source = this.audioContext.createBufferSource()
      const gainNode = this.audioContext.createGain()

      source.buffer = buffer
      gainNode.gain.value = this.masterVolume

      // è¿æ¥èŠ‚ç‚¹
      source.connect(gainNode)
      gainNode.connect(this.audioContext.destination)

      // æ’­æ”¾
      source.start()

      console.log(`ğŸ”Š æ’­æ”¾éŸ³æ•ˆ: ${soundType}`)
    } catch (error) {
      console.warn(`ğŸ”‡ éŸ³æ•ˆæ’­æ”¾å¤±è´¥: ${soundType}`, error)
    }
  }

  /**
   * è®¾ç½®éŸ³é‡
   */
  setVolume(volume: number): void {
    this.masterVolume = Math.max(0, Math.min(1, volume))
  }

  /**
   * å¯ç”¨/ç¦ç”¨éŸ³æ•ˆ
   */
  setEnabled(enabled: boolean): void {
    this.enabled = enabled
    if (enabled && !this.audioContext) {
      this.initAudioContext()
    }
  }

  /**
   * é¢„åŠ è½½æ‰€æœ‰éŸ³æ•ˆ
   */
  async preloadAll(): Promise<void> {
    if (!this.enabled) return

    const soundTypes = Object.keys(SOUND_CONFIGS) as SoundType[]
    const promises = soundTypes.map(type => this.preloadSound(type))

    try {
      await Promise.all(promises)
      console.log('ğŸ”Š æ‰€æœ‰éŸ³æ•ˆé¢„åŠ è½½å®Œæˆ')
    } catch (error) {
      console.warn('ğŸ”‡ éŸ³æ•ˆé¢„åŠ è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:', error)
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  dispose(): void {
    this.soundCache.clear()
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = null
    }
  }
}

/**
 * é»˜è®¤å¯¼å‡ºï¼šå…¨å±€éŸ³æ•ˆæ’­æ”¾å™¨å•ä¾‹
 */
export const soundPlayer = new SoundPlayer()

/**
 * ä¾¿æ·æ–¹æ³•ï¼šæ’­æ”¾éŸ³æ•ˆ
 */
export const playSound = (soundType: SoundType) => soundPlayer.playSound(soundType)